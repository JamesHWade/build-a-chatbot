[
  {
    "objectID": "slides/slides_gen-ai.html#three-ways-to-use-genai-in-rstudio",
    "href": "slides/slides_gen-ai.html#three-ways-to-use-genai-in-rstudio",
    "title": "Generative AI in RStudio",
    "section": "Three ways to use GenAI in RStudio",
    "text": "Three ways to use GenAI in RStudio\n\n\n\nGitHub Copilot\nRStudio Addins {gptstudio}, {chattr}, {gpttools}\nAPI Wrappers {openai}, {chattr}, {gptstudio}"
  },
  {
    "objectID": "slides/slides_gen-ai.html#github-copilot-integration",
    "href": "slides/slides_gen-ai.html#github-copilot-integration",
    "title": "Generative AI in RStudio",
    "section": "GitHub Copilot Integration",
    "text": "GitHub Copilot Integration\n\n\n\n\n\n\nGo watch Tom Mock’s talk to learn more Copilot in RStudio."
  },
  {
    "objectID": "slides/slides_gen-ai.html#trust-but-verify",
    "href": "slides/slides_gen-ai.html#trust-but-verify",
    "title": "Generative AI in RStudio",
    "section": "‘Trust’ but Verify",
    "text": "‘Trust’ but Verify\n\n\nGenerative AI doesn’t have a ‘brain’ or general intelligence\nIt’s just a model that’s been trained on a lot of data\nIt’s not always right, appropriate, or optimal\nIt can make up things that aren’t true, or use code that doesn’t actually exist (or run!)\nSo it’s important to verify the output before using it\nBut we can use it to quickly experiment and maybe provide a novel direction\n(basically “prompt” ourselves and our own knowledge)\n\n\n\n\nSlides Adapted from Tom Mock’s talk"
  },
  {
    "objectID": "slides/slides_gen-ai.html#what-is-copilot",
    "href": "slides/slides_gen-ai.html#what-is-copilot",
    "title": "Generative AI in RStudio",
    "section": "What is Copilot",
    "text": "What is Copilot\n\n\nGitHub Copilot is an AI pair programmer that offers autocomplete-style suggestions and real-time hints for the code you are writing by providing suggestions as “ghost text” based on the context of the surrounding code - GitHub Copilot docs\n\n\n\n\n\nAutocomplete\n\nParses code and environment\nSupplies possible completions\nStatic set of completions in popup\nIDE provided from local disk\n\n\nCopilot\n\nParses code, environment and training data\nSupplies likely completions\nDynamic set of completions via ‘ghost text’\nGenerative AI provided via API endpoint\n\n\n\n\n\n\nSlides Adapted from Tom Mock’s talk"
  },
  {
    "objectID": "slides/slides_gen-ai.html#autocomplete-vs-copilot",
    "href": "slides/slides_gen-ai.html#autocomplete-vs-copilot",
    "title": "Generative AI in RStudio",
    "section": "Autocomplete vs Copilot",
    "text": "Autocomplete vs Copilot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSlides Adapted from Tom Mock’s talk"
  },
  {
    "objectID": "slides/slides_gen-ai.html#copilot-in-rstudio",
    "href": "slides/slides_gen-ai.html#copilot-in-rstudio",
    "title": "Generative AI in RStudio",
    "section": "Copilot in RStudio",
    "text": "Copilot in RStudio\n\n\n\n\n\n\n\nSlides Adapted from Tom Mock’s talk"
  },
  {
    "objectID": "slides/slides_gen-ai.html#section-3",
    "href": "slides/slides_gen-ai.html#section-3",
    "title": "Generative AI in RStudio",
    "section": "",
    "text": "Let’s Talk Packages"
  },
  {
    "objectID": "slides/slides_gen-ai.html#gptstudio",
    "href": "slides/slides_gen-ai.html#gptstudio",
    "title": "Generative AI in RStudio",
    "section": "{gptstudio}",
    "text": "{gptstudio}"
  },
  {
    "objectID": "slides/slides_gen-ai.html#gptstudio-1",
    "href": "slides/slides_gen-ai.html#gptstudio-1",
    "title": "Generative AI in RStudio",
    "section": "{gptstudio}",
    "text": "{gptstudio}"
  },
  {
    "objectID": "slides/slides_gen-ai.html#chattr",
    "href": "slides/slides_gen-ai.html#chattr",
    "title": "Generative AI in RStudio",
    "section": "{chattr}",
    "text": "{chattr}"
  },
  {
    "objectID": "slides/slides_gen-ai.html#chattr-1",
    "href": "slides/slides_gen-ai.html#chattr-1",
    "title": "Generative AI in RStudio",
    "section": "{chattr}",
    "text": "{chattr}"
  },
  {
    "objectID": "slides/slides_gen-ai.html#gpttools",
    "href": "slides/slides_gen-ai.html#gpttools",
    "title": "Generative AI in RStudio",
    "section": "{gpttools}",
    "text": "{gpttools}"
  },
  {
    "objectID": "slides/slides_gen-ai.html#gpttools-1",
    "href": "slides/slides_gen-ai.html#gpttools-1",
    "title": "Generative AI in RStudio",
    "section": "{gpttools}",
    "text": "{gpttools}"
  },
  {
    "objectID": "slides/slides_gen-ai.html#section-4",
    "href": "slides/slides_gen-ai.html#section-4",
    "title": "Generative AI in RStudio",
    "section": "",
    "text": "GenAI in RStudio | James Wade | TunisR Users & R-Ladies Rome"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Build a Chatbot with OpenAI, Shiny, and RStudio",
    "section": "",
    "text": "My plan is to talk as little as possible and let you all play with the tools. I’ll give a brief overview of the tools and then we’ll jump into an interactive workshop where we will build a chatbot.\nIt may take a few minutes to setup your environment. The best way to do this is to clone this repo and open the project in RStudio. Here’s a link to the repo: build-a-chatbot.\n\n\nThere are two easy ways to clone the repo. You can use RStudio built-in buttons or the {usethis} package.\n\nClone with RStudioClone with {usethis}\n\n\nTo clone the repo, open RStudio and go to File &gt; New Project &gt; Version Control &gt; Git and paste in the following URL: https://github.com/JamesHWade/build-a-chatbot\n\n\n\n\n\nClone git repository with RStudio\n\n\n\n\n\n\nYou can also use the following code to clone the packages we’ll be using today.\n\n# install.packages(\"usethis\")\nrequire(usethis)\ncreate_from_github(\"jameshwade/build-a-chatbot\",\n                   fork = FALSE)\n\n\n\n\nThis repo uses {renv} to help create a reproducible environment. When you clone and open the package in RStudio, you should be prompted to install the packages. If not, you can run the following code to install the packages.\n\n# install.packages(\"renv\")\nrenv::restore()"
  },
  {
    "objectID": "index.html#the-plan-for-today",
    "href": "index.html#the-plan-for-today",
    "title": "Build a Chatbot with OpenAI, Shiny, and RStudio",
    "section": "",
    "text": "My plan is to talk as little as possible and let you all play with the tools. I’ll give a brief overview of the tools and then we’ll jump into an interactive workshop where we will build a chatbot.\nIt may take a few minutes to setup your environment. The best way to do this is to clone this repo and open the project in RStudio. Here’s a link to the repo: build-a-chatbot.\n\n\nThere are two easy ways to clone the repo. You can use RStudio built-in buttons or the {usethis} package.\n\nClone with RStudioClone with {usethis}\n\n\nTo clone the repo, open RStudio and go to File &gt; New Project &gt; Version Control &gt; Git and paste in the following URL: https://github.com/JamesHWade/build-a-chatbot\n\n\n\n\n\nClone git repository with RStudio\n\n\n\n\n\n\nYou can also use the following code to clone the packages we’ll be using today.\n\n# install.packages(\"usethis\")\nrequire(usethis)\ncreate_from_github(\"jameshwade/build-a-chatbot\",\n                   fork = FALSE)\n\n\n\n\nThis repo uses {renv} to help create a reproducible environment. When you clone and open the package in RStudio, you should be prompted to install the packages. If not, you can run the following code to install the packages.\n\n# install.packages(\"renv\")\nrenv::restore()"
  },
  {
    "objectID": "index.html#create-accounts-and-set-api-keys",
    "href": "index.html#create-accounts-and-set-api-keys",
    "title": "Build a Chatbot with OpenAI, Shiny, and RStudio",
    "section": "Create Accounts and Set API Keys",
    "text": "Create Accounts and Set API Keys\nWith {gptstudio} and {gpttools}, you can use any of seven AI services. You’ll need to create an account with the service you want to use. Here’s a list of the services and links to the documentation and setup instructions:\n\n\n\nAI Service\nModels\nDocumentation\n\n\n\n\nOpenAI\ngpt-4-turbo, gpt-4, gpt-3.5-turbo (latest models)\nOpenAI API Docs\n\n\nHuggingFace\nvarious\nHF Inference API Docs\n\n\nAnthropic\nclaude-2.1, claude-instant-1.2\nAnthropic API Docs\n\n\nOllama\nmistral, llama2, mixtral, phi (latest models)\nOllama API Docs\n\n\nPerplexity\npplx-7b-chat, pplx-70b-chat, pplx-7b-online, pplx-70b-online, llama-2-70b-chat, codellama-34b-instruct, mistral-7b-instruct, and mixtral-8x7b-instruct\nPerplexity API Docs\n\n\nGoogle AI Studio\nGemini and Palm (legacy)\nGoogle AI Studio Docs\n\n\nAzure OpenAI\ngpt-4, gpt-3.5-turbo (latest models)\nAzure OpenAI API Docs\n\n\n\nFollow instructions for your chosen service to create an account and get an API key. You’ll need to add the API key to your .Renviron file. Here are instructions for each service:\n\nOpenAIHuggingFaceAnthropicOllamaPerplexityGoogle AI StudioAzure OpenAI\n\n\n\nCreating an OpenAI Account\n\nVisit OpenAI’s website and sign up for an account.\nFollow the instructions to verify your account.\n\n\n\nCreating an OpenAI API Key\n\nOnce logged in, navigate to the API section in your account settings.\nFollow the instructions to create a new API key. More detailed steps can be found in OpenAI’s API documentation.\n\n\n\nSetting the OpenAI API Key in .Renviron\nTo modify the .Renviron file:\n\nrequire(usethis) \nedit_r_environ()\n\nFor a persistent setting, add the following line to .Renviron, replacing \"&lt;APIKEY&gt;\" with your actual API key:\nOPENAI_API_KEY=\"&lt;APIKEY&gt;\"\nSave the file and restart your R session for the changes to take effect.\nCaution: Ensure .Renviron is included in your .gitignore file to avoid exposing your API key with version control systems like GitHub or GitLab.\nImportant Note: OpenAI API requires valid payment details in your OpenAI account to function. This is a restriction imposed by OpenAI and is unrelated to this package.\n\n\n\n\nCreating a HuggingFace Account\n\nVisit HuggingFace’s website and sign up for an account.\nComplete the account verification process.\n\n\n\nCreating a HuggingFace API Key\n\nAfter logging in, go to your account settings.\nFind the section for API keys and create a new one. Detailed guidance is available in HuggingFace’s API documentation.\n\n\n\nSetting the HuggingFace API Key in .Renviron\nTo modify the .Renviron file:\n\nrequire(usethis)\nedit_r_environ()\n\nFor a persistent setting, add the following line to .Renviron, replacing \"&lt;APIKEY&gt;\" with your actual HuggingFace API key:\nHF_API_KEY=\"&lt;APIKEY&gt;\"\nSave the file and restart your R session for the changes to take effect.\nCaution: Remember to include .Renviron in your .gitignore file to prevent exposing your API key, especially if using version control systems like GitHub or GitLab.\n\n\n\n\nCreating an Anthropic Account\n\nGo to the Anthropic website and sign up.\nVerify your account as instructed.\n\n\n\nCreating an Anthropic API Key\n\nLog into your Anthropic account and navigate to the API section.\nCreate an API key following their guidelines. Check Anthropic’s API documentation for more details.\n\n\n\nSetting the Anthropic API Key in .Renviron\nTo modify the .Renviron file:\n\nrequire(usethis)\nedit_r_environ()\n\nFor a persistent setting, add the following line to .Renviron, replacing \"&lt;APIKEY&gt;\" with your actual Anthropic API key:\nANTHROPIC_API_KEY=\"&lt;APIKEY&gt;\"\nSave the file and restart your R session for the changes to take effect.\nCaution: Ensure .Renviron is not exposed if using version control systems.\n\n\n\nThe ollama service allows you to run open source LLMs locally, providing a command line interface and an API. By wrapping the later, we can use it within our chat app.\nYou can run ollama in any platform as a docker container. The following code runs the CPU-only version:\ndocker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\nThis code:\n\npulls the latest ollama image from the ollama hub (ollama/ollama)\nexposes the ollama API in http://localhost:11434 (-p 11434:11434)\nsets up the ollama volume, to be used in the “/root/.ollama” path inside the container. this will allow you to update the container later without losing your already downloaded models. (-v ollama:/root/.ollama)\nassigns the name “ollama” to the container (--name ollama)\nruns the container in detached mode (docker run -d)\n\nYou can see more docker options in the official blog post.\nBefore using the service, you need to pull a model. Run the following code inside your container to pull llama2:\nollama pull llama2\nCheck the ollama library to see more models. For more advanced install options, check the official documentation.\nBy default, the chat addin will use http://localhost:11434 to locate the ollama API. You can customize this by setting up the OLLAMA_HOST environmental variable with usethis::edit_r_environ().\n\nAn Example with Ollama\nHere is a short video showing you how to get started with ollama. It assumes that you have already installed docker. See the docker installation guide for more information.\n\n\n\n\n\nCreating an Perplexity Account\n\nGo to the Perplexity website and sign up.\nVerify your account as instructed.\n\n\n\nCreating an Perplexity API Key\n\nLog into your Perplexity account and navigate to the API documentation.\nCreate an API key following their guidelines. Check Perplexity’s API documentation for more details.\n\n\n\nSetting the Perplexity API Key in .Renviron\nTo modify the .Renviron file:\n\nrequire(usethis)\nedit_r_environ()\n\nFor a persistent setting, add the following line to .Renviron, replacing \"&lt;APIKEY&gt;\" with your actual Perplexity API key:\nPERPLEXITY_API_KEY=\"&lt;APIKEY&gt;\"\nSave the file and restart your R session for the changes to take effect.\nCaution: Ensure .Renviron is not exposed if using version control systems.\n\n\n\n\nCreating an Account in Google’s AI Studio\n\nVisit Google’s AI Studio website and sign up.\nComplete the verification process.\n\n\n\nAccessing Google PALM API\n\nIn your Google Cloud Console, enable the PALM API.\nCreate an API key as per the instructions in Google’s API documentation.\n\n\n\nSetting the Google AI Studio API Key in .Renviron\nTo modify the .Renviron file:\n\nrequire(usethis)\nedit_r_environ()\n\nFor a persistent setting, add the following line to .Renviron, replacing \"&lt;APIKEY&gt;\" with your actual Google PALM API key:\nPALM_API_KEY=\"&lt;APIKEY&gt;\"\nSave the file and restart your R session for the changes to take effect.\nCaution: Be careful not to expose .Renviron in public repositories or version control systems to protect your API key.\n\n\n\nTo configure gptstudio to work using Azure OpenAI service, you need to provide some configuration details in your .Renviron file. Specifically, gptstudio looks for five environment variables:\n\nAZURE_OPENAI_TASK\nAZURE_OPENAI_ENDPOINT\nAZURE_OPENAI_DEPLOYMENT_NAME\nAZURE_OPENAI_KEY\nAZURE_OPENAI_API_VERSION\n\nHere’s how you can add these details to your .Renviron file:\n\nLocate your .Renviron file with usethis::edit_r_environ().\nAdd environment variable details: Add a new line for each variable you need to set in the following format: VARIABLE_NAME=“YOUR_VALUE”. Replace VARIABLE_NAME with the name of the environment variable and YOUR_VALUE with the actual value that you want to set. For example, to set the API key you would have a line like this:\n\nAZURE_OPENAI_KEY=\"your_actual_key_goes_here\"\nYou need to do this for each of the environment variables expected by the function. Your .Renviron file should look something like this:\nAZURE_OPENAI_TASK=\"your_task_code\"\nAZURE_OPENAI_ENDPOINT=\"your_endpoint_url\"\nAZURE_OPENAI_DEPLOYMENT_NAME=\"your_deployment_name\"\nAZURE_OPENAI_KEY=\"your_api_key\"\nAZURE_OPENAI_API_VERSION=\"your_api_version\"\n\nSave and Close .Renviron: After adding your environment variables, save your .Renviron file and close it. You will need to restart your R session to make sure the new environment variables are loaded properly.\n\nRemember to replace your_task_code, your_endpoint_url, your_deployment_name, your_api_key, and your_api_version with your actual Azure OpenAI details. You can retrieve these details from your Azure OpenAI service account. For more information about Azure OpenAI configuration, refer to the Microsoft quickstart guide."
  },
  {
    "objectID": "index.html#suggested-resources",
    "href": "index.html#suggested-resources",
    "title": "Build a Chatbot with OpenAI, Shiny, and RStudio",
    "section": "Suggested Resources",
    "text": "Suggested Resources\n\nGitHub Copilot in RStudio, it’s finally here! by Tom Mock, Product Manager of RStudio Workbench\n{gptstudio} - An R package that integrates LLMs into RStudio\n{gpttools} - A sister package to {gptstudio} that allows RAG to supplement LLMs\n{chattr} - A package from the mlverse team to integrates LLM’s with the RStudio by Edgar Ruiz, Posit Software Engineer"
  },
  {
    "objectID": "index.html#slides-for-today",
    "href": "index.html#slides-for-today",
    "title": "Build a Chatbot with OpenAI, Shiny, and RStudio",
    "section": "Slides for Today",
    "text": "Slides for Today\n\nPart 1: Generative AI in RStudio\n\n\n\n\n\n View all slides in new window\n\n\nPart 2: Let’s Build a Chatbot\n\n\n\n\n\n View all slides in new window"
  },
  {
    "objectID": "slides/slides_chat-bot.html#api-calls",
    "href": "slides/slides_chat-bot.html#api-calls",
    "title": "Let’s Build a Chatbot",
    "section": "API Calls",
    "text": "API Calls"
  },
  {
    "objectID": "slides/slides_chat-bot.html#an-example-from-openai-docs",
    "href": "slides/slides_chat-bot.html#an-example-from-openai-docs",
    "title": "Let’s Build a Chatbot",
    "section": "An Example from OpenAI Docs",
    "text": "An Example from OpenAI Docs\n\ncurl https://api.openai.com/v1/chat/completions \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-d '{\n\"model\": \"gpt-3.5-turbo\",\n\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Hello!\"}]\n}'"
  },
  {
    "objectID": "slides/slides_chat-bot.html#constructing-messages-for-openai",
    "href": "slides/slides_chat-bot.html#constructing-messages-for-openai",
    "title": "Let’s Build a Chatbot",
    "section": "Constructing Messages for OpenAI",
    "text": "Constructing Messages for OpenAI\n\nThe message body:\n{\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ]\n}"
  },
  {
    "objectID": "slides/slides_chat-bot.html#send-requests-with-httr2",
    "href": "slides/slides_chat-bot.html#send-requests-with-httr2",
    "title": "Let’s Build a Chatbot",
    "section": "Send requests with {httr2}",
    "text": "Send requests with {httr2}\n\nlibrary(httr2)\nlibrary(purrr)"
  },
  {
    "objectID": "slides/slides_chat-bot.html#send-requests-with-httr2-1",
    "href": "slides/slides_chat-bot.html#send-requests-with-httr2-1",
    "title": "Let’s Build a Chatbot",
    "section": "Send requests with {httr2}",
    "text": "Send requests with {httr2}\n\nlibrary(httr2)\nlibrary(purrr)\n\n# construct the message body\nuser_message &lt;- list(list(role = \"user\", content = \"Hello\"))\nbody &lt;- list(model = \"gpt-3.5-turbo\", messages = user_message)"
  },
  {
    "objectID": "slides/slides_chat-bot.html#send-requests-with-httr2-2",
    "href": "slides/slides_chat-bot.html#send-requests-with-httr2-2",
    "title": "Let’s Build a Chatbot",
    "section": "Send requests with {httr2}",
    "text": "Send requests with {httr2}\n\nlibrary(httr2)\nlibrary(purrr)\n\n# construct the message body\nuser_message &lt;- list(list(role = \"user\", content = \"Hello!\"))\nbody &lt;- list(model = \"gpt-3.5-turbo\", messages = user_message)\n\n# send the request\nresp &lt;-\n  request(\"https://api.openai.com/v1\") |&gt; \n  req_url_path_append(\"chat/completions\") |&gt; \n  req_auth_bearer_token(token = Sys.getenv(\"OPENAI_API_KEY\")) |&gt; \n  req_body_json(body) |&gt; \n  req_perform()"
  },
  {
    "objectID": "slides/slides_chat-bot.html#send-requests-with-httr2-3",
    "href": "slides/slides_chat-bot.html#send-requests-with-httr2-3",
    "title": "Let’s Build a Chatbot",
    "section": "Send requests with {httr2}",
    "text": "Send requests with {httr2}\n\nlibrary(httr2)\nlibrary(purrr)\n\n# construct the message body\nuser_message &lt;- list(list(role = \"user\", content = \"Hello!\"))\nbody &lt;- list(model = \"gpt-3.5-turbo\", messages = user_message)\n\n# send the request\nresp &lt;-\n  request(\"https://api.openai.com/v1\") |&gt;\n  req_url_path_append(\"chat/completions\") |&gt; \n  req_auth_bearer_token(token = Sys.getenv(\"OPENAI_API_KEY\")) |&gt; \n  req_body_json(body) |&gt; \n  req_perform()\n\n# process the response\nresp |&gt;\n  resp_body_json(simplifyVector = TRUE) |&gt; \n  pluck(\"choices\", \"message\", \"content\")\n\n[1] \"Hello! How can I assist you today?\""
  },
  {
    "objectID": "slides/slides_chat-bot.html#examining-the-response",
    "href": "slides/slides_chat-bot.html#examining-the-response",
    "title": "Let’s Build a Chatbot",
    "section": "Examining the Response",
    "text": "Examining the Response\n\nresp |&gt; \n  resp_body_json(simplifyVector = TRUE)\n\n$id\n[1] \"chatcmpl-8tIGZLfmm3u3NuDC16ElF5CrWBHuF\"\n\n$object\n[1] \"chat.completion\"\n\n$created\n[1] 1708188947\n\n$model\n[1] \"gpt-3.5-turbo-0125\"\n\n$choices\n  index message.role                    message.content logprobs finish_reason\n1     0    assistant Hello! How can I assist you today?       NA          stop\n\n$usage\n$usage$prompt_tokens\n[1] 9\n\n$usage$completion_tokens\n[1] 9\n\n$usage$total_tokens\n[1] 18\n\n\n$system_fingerprint\n[1] \"fp_69829325d0\""
  },
  {
    "objectID": "slides/slides_chat-bot.html#wrapping-it-in-a-function",
    "href": "slides/slides_chat-bot.html#wrapping-it-in-a-function",
    "title": "Let’s Build a Chatbot",
    "section": "Wrapping it in a function",
    "text": "Wrapping it in a function\n\nlibrary(httr2)\nlibrary(purrr)\n\nchat &lt;- function(message, api_key = Sys.getenv(\"OPENAI_API_KEY\")) {\n  user_message &lt;- list(list(role = \"user\", content = message))\n  body &lt;- list(model = \"gpt-3.5-turbo\",\n               messages = user_message)\n  resp &lt;-\n    request(\"https://api.openai.com/v1\") |&gt; \n    req_url_path_append(\"chat/completions\") |&gt; \n    req_auth_bearer_token(token = api_key) |&gt; \n    req_body_json(body) |&gt; \n    req_perform()\n  \n  resp |&gt; \n    resp_body_json(simplifyVector = TRUE) |&gt; \n    pluck(\"choices\", \"message\", \"content\")\n}"
  },
  {
    "objectID": "slides/slides_chat-bot.html#lets-try-it-out",
    "href": "slides/slides_chat-bot.html#lets-try-it-out",
    "title": "Let’s Build a Chatbot",
    "section": "Let’s Try it Out",
    "text": "Let’s Try it Out"
  },
  {
    "objectID": "slides/slides_chat-bot.html#trying-out-chat",
    "href": "slides/slides_chat-bot.html#trying-out-chat",
    "title": "Let’s Build a Chatbot",
    "section": "Trying out chat()",
    "text": "Trying out chat()\n\n\nchat(\"What is your favorite color?\")\n\n[1] \"I'm a language model AI from OpenAI, so I don't have personal preferences or feelings like humans do. But I can certainly appreciate all the beautiful colors in the world! What's your favorite color?\"\n\n\n\n\n\nchat(\"Show me a simple ggplot2 example. Only code with comments. Be brief.\")\n\n[1] \"```\\n# Load ggplot2 package\\nlibrary(ggplot2)\\n\\n# Create a simple scatter plot\\nggplot(mtcars, aes(x = mpg, y = wt)) + \\n  geom_point()\\n```\""
  },
  {
    "objectID": "slides/slides_chat-bot.html#a-prettier-response",
    "href": "slides/slides_chat-bot.html#a-prettier-response",
    "title": "Let’s Build a Chatbot",
    "section": "A Prettier Response",
    "text": "A Prettier Response\n\nanswer &lt;- chat(\"Make a ggplot2 in an RMarkdown document and briefly tell me\n               what you made.\")\nanswer |&gt; cat()\n\n```{r}\nlibrary(ggplot2)\n\n# Create a scatter plot of car weights and miles per gallon\nggplot(mpg, aes(x = wt, y = hwy)) +\n  geom_point() +\n  labs(title = \"Car Weight vs. Miles Per Gallon\",\n       x = \"Weight (in 1000 lbs)\",\n       y = \"Highway MPG\")\n```\n\nIn this ggplot2 visualization, I created a scatter plot comparing car weights (in 1000 lbs) on the x-axis to highway miles per gallon (MPG) on the y-axis using the `mpg` dataset that comes with ggplot2. Each point represents a different car, showing the relationship between weight and fuel efficiency. The plot title and axis labels provide context for the viewer."
  },
  {
    "objectID": "slides/slides_chat-bot.html#an-even-prettier-response",
    "href": "slides/slides_chat-bot.html#an-even-prettier-response",
    "title": "Let’s Build a Chatbot",
    "section": "An Even Prettier Response",
    "text": "An Even Prettier Response\n\n\nlibrary(ggplot2)\n\n# Create a scatter plot of car weights and miles per gallon\nggplot(mpg, aes(x = wt, y = hwy)) +\n  geom_point() +\n  labs(title = \"Car Weight vs. Miles Per Gallon\",\n       x = \"Weight (in 1000 lbs)\",\n       y = \"Highway MPG\")\n\nIn this ggplot2 visualization, I created a scatter plot comparing car weights (in 1000 lbs) on the x-axis to highway miles per gallon (MPG) on the y-axis using the mpg dataset that comes with ggplot2. Each point represents a different car, showing the relationship between weight and fuel efficiency. The plot title and axis labels provide context for the viewer."
  },
  {
    "objectID": "slides/slides_chat-bot.html#helper-functions",
    "href": "slides/slides_chat-bot.html#helper-functions",
    "title": "Let’s Build a Chatbot",
    "section": "Helper Functions",
    "text": "Helper Functions"
  },
  {
    "objectID": "slides/slides_chat-bot.html#chat",
    "href": "slides/slides_chat-bot.html#chat",
    "title": "Let’s Build a Chatbot",
    "section": "chat()",
    "text": "chat()\nchat &lt;- function(user_message, \n                 history = NULL,\n                 system_prompt = c(\"general\", \"code\"),\n                 api_key = Sys.getenv(\"OPENAI_API_KEY\")) {\n  system   &lt;- get_system_prompt(system_prompt)\n  prompt   &lt;- prepare_prompt(user_message, system_prompt, history)\n  base_url &lt;- \"https://api.openai.com/v1\"\n  body     &lt;- list(model = \"gpt-3.5-turbo\",\n                   messages = prompt)\n  \n  # &lt;httr2_request_pipeline&gt;\n  # &lt;process_response&gt;\n}"
  },
  {
    "objectID": "slides/slides_chat-bot.html#helper-functions-1",
    "href": "slides/slides_chat-bot.html#helper-functions-1",
    "title": "Let’s Build a Chatbot",
    "section": "Helper Functions",
    "text": "Helper Functions\nget_system_prompt()\nget_system_prompt &lt;- function(system = c(\"general\", \"code\")) {\n  instructions &lt;- \n    switch(system,\n           \"general\" = \"You are a helpful assistant.\",\n           \"code\"    = \"&lt;code_assistant_prompt&gt;\")\n  list(list(role = \"system\", content = instructions))\n}\n\nprepare_prompt()\nprepare_prompt &lt;- function(user_message, system_prompt, history) {\n  user_prompt &lt;-  list(list(role = \"user\", content = user_message))\n  c(system_prompt, history, user_prompt) |&gt; compact()\n}"
  },
  {
    "objectID": "slides/slides_chat-bot.html#shiny-build",
    "href": "slides/slides_chat-bot.html#shiny-build",
    "title": "Let’s Build a Chatbot",
    "section": "Shiny Build",
    "text": "Shiny Build\n\n\n\n−+\n30:00"
  },
  {
    "objectID": "slides/slides_chat-bot.html#deployment",
    "href": "slides/slides_chat-bot.html#deployment",
    "title": "Let’s Build a Chatbot",
    "section": "Deployment",
    "text": "Deployment\n\n\n\nshinyapps.io 🔗\nHuggingFace 🔗\nPosit Connect 🔗"
  },
  {
    "objectID": "slides/slides_chat-bot.html#section",
    "href": "slides/slides_chat-bot.html#section",
    "title": "Let’s Build a Chatbot",
    "section": "",
    "text": "Let’s Build a Chatbot | James Wade | TunisR Users & R-Ladies Rome"
  }
]